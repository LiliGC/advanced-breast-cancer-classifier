# ğŸ©º Clasificador Avanzado de CÃ¡ncer de Mama

[![CI/CD to Google Cloud](https://github.com/LiliGC/advanced-breast-cancer-classifier/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/LiliGC/advanced-breast-cancer-classifier/actions/workflows/ci-cd.yml)

Una aplicaciÃ³n completa de Machine Learning para la clasificaciÃ³n de tumores de mama usando Random Forest optimizado, con API Flask y frontend interactivo en Streamlit, todo orquestado con Docker.

## âœ¨ CaracterÃ­sticas Principales
- **Dataset**: Wisconsin Breast Cancer Dataset (WDBC) de UCI.
### ğŸ¤– Modelo de ML Mejorado
- **Random Forest optimizado** con GridSearchCV.
- **ValidaciÃ³n cruzada** y mÃ©tricas comprehensivas (Accuracy, ROC-AUC, Recall).
- **AnÃ¡lisis de importancia de features** para explicabilidad.
- **GeneraciÃ³n automÃ¡tica de visualizaciones**: Curva ROC, matriz de confusiÃ³n, etc.
- **CreaciÃ³n de casos de ejemplo** (benigno, maligno, lÃ­mite) basados en datos reales para demostraciones consistentes.

### ğŸŒ API REST Robusta
- **Endpoints**: `health`, `model/info`, `features`, `predict` (individual y batch), y `visualizations`.
- **ValidaciÃ³n robusta** de datos de entrada y manejo de errores.
- **CÃ¡lculo de contribuciÃ³n de features** para cada predicciÃ³n.
- **Logging** para seguimiento y depuraciÃ³n.

### ğŸ¯ Frontend Interactivo
- **4 pestaÃ±as especializadas**:
  - ğŸ” PredicciÃ³n con casos predefinidos
  - ğŸ“Š AnÃ¡lisis de features del dataset
  - ğŸ›ï¸ Modo manual con sliders interactivos
  - ğŸ“ˆ Visualizaciones del modelo
- **GrÃ¡ficos interactivos** con Plotly
- **MÃ©tricas en tiempo real**
- **Interfaz intuitiva y profesional** con CSS personalizado.

### ğŸ³ ContenerizaciÃ³n con Docker
- **Pipeline reproducible** con Docker Compose.
- **4 servicios definidos**: `training`, `api`, `frontend`, y `tester`.
- **Inicio automatizado** con un solo script (`start.sh`).
- **Pruebas de integraciÃ³n** automatizadas contra la API en un entorno aislado.

### ğŸš€ CI/CD y Despliegue en la Nube
- **Pipeline Automatizado con GitHub Actions**: Cada `push` a la rama `main` dispara un flujo de trabajo que automÃ¡ticamente entrena, prueba, construye y despliega la aplicaciÃ³n.
- **Despliegue en Google Cloud**: La aplicaciÃ³n se despliega en **Google Cloud Run**, una plataforma serverless que escala automÃ¡ticamente, garantizando alta disponibilidad y eficiencia.
- **Registro de ImÃ¡genes en Artifact Registry**: Las imÃ¡genes de Docker se versionan y almacenan de forma segura en Google Artifact Registry.


## ğŸ¥ DemostraciÃ³n

A continuaciÃ³n se presentan breves demostraciones de la aplicaciÃ³n.

### Frontend Interactivo

Un vistazo rÃ¡pido a la interfaz de usuario, mostrando una predicciÃ³n en tiempo real y el dashboard de resultados.

**â¡ï¸ [Ver Demo Completa del Frontend en YouTube](https://youtu.be/sKUN_uGA1IQ)**

### Backend y Pruebas

DemostraciÃ³n de la interacciÃ³n entre la API, los contenedores y las pruebas automatizadas.

**â¡ï¸ [Ver Demo Completa del Backend en YouTube](https://youtu.be/5-SuQPW3JMw)**

## ğŸš€ InstalaciÃ³n y Uso RÃ¡pido (con Docker)

Este proyecto estÃ¡ diseÃ±ado para ejecutarse con Docker, lo que simplifica enormemente la configuraciÃ³n y garantiza la reproducibilidad.

**Requisitos:**
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado y en ejecuciÃ³n.
- Un terminal que soporte scripts de shell (Git Bash o WSL en Windows).

**Pasos para ejecutar:**

1.  **Clonar el Repositorio:**
    ```bash
    git clone https://github.com/LiliGC/advanced-breast-cancer-classifier.git
    cd advanced-breast-cancer-classifier
    ```

2.  **Ejecutar el Script de OrquestaciÃ³n:**
    El mÃ©todo recomendado es utilizar el script `start.sh` que gestiona todo el ciclo de vida de la aplicaciÃ³n local.
    Este script actÃºa como un orquestador que ejecuta los comandos de `docker-compose` en la secuencia correcta para asegurar un inicio limpio y ordenado.

    ```bash
    # En Windows (usando Git Bash o WSL) o en Linux/macOS
    ./start.sh
    ```
    Este script se encargarÃ¡ de:
    - Limpiar entornos Docker previos.
    - Construir las imÃ¡genes necesarias.
    - Ejecutar el contenedor de entrenamiento para generar los artefactos del modelo.
    - Levantar la API y el Frontend.
    - Ejecutar las pruebas de integraciÃ³n contra la API.

3.  **Acceder a la AplicaciÃ³n:**
    - **Frontend:** Abre tu navegador y ve a `http://localhost:8501`
    - **API Health Check:** `http://localhost:5000/health`

### ğŸ› ï¸ Flujo de Desarrollo Diario

Una vez que la aplicaciÃ³n ha sido construida y entrenada con `start.sh`, no necesitas ejecutar todo el script cada vez.

- **Para iniciar solo la API y el Frontend (sin re-entrenar):**
  ```bash
  docker-compose up -d api frontend
  ```
- **Para detener todos los servicios:**
  ```bash
  docker-compose down
  ```
#### Limpieza del Entorno

Si deseas eliminar los contenedores, volÃºmenes y las imÃ¡genes construidas para liberar espacio en tu disco:

1.  **Detener y eliminar contenedores y volÃºmenes:**
    ```bash
    docker-compose down -v
    ```

2.  **Eliminar las imÃ¡genes construidas por el proyecto:**
    ```bash
    # Reemplaza 'breast_cancer_project' si tu carpeta de proyecto tiene otro nombre
    docker rmi $(docker images -q 'breast_cancer_project*')
    ```
## ğŸ“‹ Estructura del Proyecto

```
breast_cancer_project/
ğŸ“ .github/
â”‚   â”œâ”€â”€ ğŸ“ workflows
â”‚   â”‚   â”œâ”€â”€ ci-cd.yml          # Flujo de trabajo de CI/CD
â”œâ”€â”€ ğŸ“ breast_cancer_app/
â”‚   â”œâ”€â”€ ğŸ“ model
â”‚   â”‚   â”œâ”€â”€ train_model.py     # Script de entrenamiento
â”‚   â”œâ”€â”€ ğŸ“ api
â”‚   â”‚   â”œâ”€â”€ api.py              # API Flask
|   â”œâ”€â”€ ğŸ“ frontend
â”‚   â”‚   â”œâ”€â”€ frontend.py         # Frontend Streamlit
â”œâ”€â”€ ğŸ“ tests
â”‚   â”‚   â”œâ”€â”€ test_api.py         # Tests automatizados
â”œâ”€â”€ ğŸ“ requirements/
â”‚   â”œâ”€â”€ common.txt              # Dependencias comunes
â”‚   â”œâ”€â”€ api.txt                 # Dependencias de la API
â”‚   â”œâ”€â”€ frontend.txt            # Dependencias del Frontend
â”‚   â””â”€â”€ dev.txt                 # Dependencias de desarrollo
â”œâ”€â”€ ğŸ“ artifacts (automÃ¡tico)
â”‚   â”œâ”€â”€ model.pkl  # Modelo entrenado
â”‚   â”œâ”€â”€ feature_info.json         # Info de features
â”‚   â”œâ”€â”€ model_metrics.json        # MÃ©tricas
â”‚   â””â”€â”€ *.png                    # Visualizaciones
|___ğŸ“ docs/
|    â””â”€â”€ DEVELOPMENT_GUIDE.md    # GuÃ­a de evoluciÃ³n del desarrollo del proyecto
|â”€â”€ Dockerfile                   # Dockerfile para la API
|â”€â”€ Docker-compose.yml           # Orquestador de contenedores
|â”€â”€ .dockerignore                # Archivos a ignorar en Docker
|â”€â”€ .gitignore                   # Archivos a ignorar en Git
|â”€â”€ start.sh                     # Script de inicio automatizado
|â”€â”€ README.md                    # DocumentaciÃ³n del proyecto
```

## ğŸ”§ Componentes Detallados

### 1. ğŸ¤– Entrenamiento del Modelo (`breast_cancer_app/model/train_model.py`)

**CaracterÃ­sticas:**
- **OptimizaciÃ³n de hiperparÃ¡metros** con GridSearchCV.
- **ValidaciÃ³n cruzada** para evaluar la generalizaciÃ³n del modelo.
- **MÃ©tricas completas**: Accuracy, ROC-AUC, y reporte de clasificaciÃ³n.
- **AnÃ¡lisis de importancia de features** para explicabilidad.
- **GeneraciÃ³n automÃ¡tica de visualizaciones**: Curva ROC, matriz de confusiÃ³n, etc.

**Archivos generados en `artifacts/`:**
- `model.pkl` - El modelo entrenado y serializado.
- `roc_curve.png` - Curva ROC del modelo.
- `confusion_matrix.png` - Matriz de confusiÃ³n en el set de prueba.

### 2. ğŸŒ API REST (`breast_cancer_app/api/api.py`)
- **Endpoints**: `health`, `model/info`, `features`, `predict` (individual y batch), y `visualizations`.
- **ValidaciÃ³n robusta** de datos de entrada.
- **CÃ¡lculo de contribuciÃ³n de features** para cada predicciÃ³n.
- **Logging** para seguimiento y depuraciÃ³n.

### 3. ğŸ¯ Frontend Interactivo (`breast_cancer_app/frontend/frontend.py`)
- **NavegaciÃ³n por pestaÃ±as**: Inicio, PredicciÃ³n, AnÃ¡lisis del Dataset y Rendimiento del Modelo.
- **Dashboard de resultados** con medidor de confianza y factores clave.
- **Visualizaciones interactivas** con Plotly para explorar el dataset y el modelo.
- **DiseÃ±o profesional** y responsivo con CSS personalizado.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **ML**: scikit-learn, pandas, numpy
- **Backend**: Flask, Flask-CORS
- **Frontend**: Streamlit, Plotly, Altair
- **VisualizaciÃ³n**: matplotlib, seaborn
- **CI/CD**: GitHub Actions
- **Cloud**: Google Cloud Run, Google Artifact Registry
- **Testing**: requests, pytest
- **Utilidades**: joblib, json

## ğŸ¯ Casos de Uso

1. **ğŸ©º MÃ©dicos**: Herramienta de apoyo diagnÃ³stico
2. **ğŸ“ Estudiantes**: Aprender ML aplicado
3. **ğŸ‘¨â€ğŸ’» Desarrolladores**: Plantilla para proyectos de ML
4. **ğŸ”¬ Investigadores**: AnÃ¡lisis de features biomÃ©dicas

## ğŸ“ˆ MÃ©tricas de Rendimiento

El modelo optimizado tÃ­picamente alcanza:
- **Accuracy**: >95%
- **ROC-AUC**: >98%
- **Tiempo de predicciÃ³n**: <100ms
- **Memoria**: <50MB

## ğŸ¤ Contribuir

Â¡Las contribuciones para mejorar este proyecto son bienvenidas!

**Posibles extensiones:**
- ğŸ§  **Explicabilidad Avanzada**: Integrar librerÃ­as como **SHAP** para generar visualizaciones de contribuciÃ³n mÃ¡s detalladas por predicciÃ³n.
- ğŸ¨ **Mejoras en la UI/UX**: AÃ±adir temas, mejorar la responsividad o incorporar nuevos tipos de grÃ¡ficos.
- ğŸ“Š **Monitoreo del Modelo**: Integrar la API con **Vertex AI Model Monitoring** para detectar *data drift* y *concept drift* en producciÃ³n, registrando predicciones en BigQuery.
- ğŸ—„ï¸ **Historial de Predicciones**: AÃ±adir una base de datos (como SQLite o PostgreSQL) para guardar y consultar predicciones pasadas.

## ğŸ“ Troubleshooting y Soporte

Si encuentras algÃºn problema al ejecutar el proyecto localmente, sigue estos pasos:

1.  **AsegÃºrate de usar el script `start.sh`**: Este script garantiza que el entorno se limpie y se construya en el orden correcto. Es la forma recomendada de iniciar la aplicaciÃ³n.

2.  **Revisar los Logs de Docker**: Si un servicio no se inicia o se comporta de forma extraÃ±a, los logs son tu mejor amigo. Abre una nueva terminal y ejecuta:
    ```bash
    # Para ver los logs de la API
    docker-compose logs api

    # Para ver los logs del frontend
    docker-compose logs frontend
    ```

3.  **ReconstrucciÃ³n Forzada**: Si has hecho cambios en el cÃ³digo y no se reflejan, es posible que necesites forzar una reconstrucciÃ³n. El script `start.sh` ya lo hace, pero si quieres hacerlo manualmente:
    ```bash
    docker-compose build --no-cache
    ```

4.  **Abrir un Issue**: Si el problema persiste, la mejor manera de reportarlo es creando un "Issue" en el repositorio de GitHub. Por favor, incluye la salida de los logs y los pasos que seguiste.

## ğŸ—ï¸ CI/CD y Despliegue en la Nube

### Flujo de Trabajo de CI/CD con GitHub Actions

Este proyecto utiliza un pipeline de IntegraciÃ³n Continua y Despliegue Continuo (CI/CD) para automatizar todo el ciclo de vida de la aplicaciÃ³n.

1.  **ActivaciÃ³n**: El flujo de trabajo se activa con cada `push` a la rama `main`.
2.  **Entrenamiento y Pruebas**: Se ejecuta el script de entrenamiento para generar los artefactos del modelo y se realizan pruebas de integraciÃ³n contra la API.
3.  **ConstrucciÃ³n de ImÃ¡genes**: Se construyen las imÃ¡genes de Docker para la API y el frontend.
4.  **PublicaciÃ³n**: Las imÃ¡genes se etiquetan y se suben a Google Artifact Registry.
5.  **Despliegue**: Se despliegan las nuevas versiones de los servicios en Google Cloud Run, actualizando la aplicaciÃ³n sin tiempo de inactividad.

### Despliegue en Google Cloud (ConfiguraciÃ³n)

El pipeline estÃ¡ preparado para desplegar automÃ¡ticamente en Google Cloud usando **Workload Identity Federation**, un mÃ©todo seguro que no requiere claves de servicio de larga duraciÃ³n.

**Pasos a seguir en Google Cloud (Resumen):**

1.  **Crear un Proyecto y Habilitar APIs**:
    - Crea un nuevo proyecto en la Consola de Google Cloud.
    - Habilita las siguientes APIs: `Cloud Run API`, `Artifact Registry API`, y `IAM Credentials API`.

2.  **Crear Repositorios en Artifact Registry**:
    - Crea dos repositorios de tipo Docker en Artifact Registry: uno llamado `api-repo` y otro `frontend-repo`.

3.  **Configurar la Identidad para el Pipeline**:
    - **Crea una Cuenta de Servicio (Service Account)**, por ejemplo, `github-actions-deployer`.
    - **Otorga los roles necesarios** a esta cuenta de servicio: `Cloud Run Admin`, `Artifact Registry Writer`, y `Service Account User`.
    - **Crea un Workload Identity Pool y un Provider**. Configura el proveedor para que confÃ­e en tu repositorio de GitHub.
    - **Vincula la Cuenta de Servicio** a la identidad de GitHub, otorgÃ¡ndole el rol `Workload Identity User`. Esto permite que GitHub Actions actÃºe en nombre de tu cuenta de servicio de forma segura.

**Pasos a seguir en GitHub:**

1.  **Configurar los Secretos**: Ve a `Settings > Secrets and variables > Actions` en tu repositorio y aÃ±ade los siguientes secretos, que obtuviste de los pasos anteriores en Google Cloud:
    - `GCP_PROJECT_ID`
    - `GCP_WORKLOAD_IDENTITY_PROVIDER`
    - `GCP_SERVICE_ACCOUNT`

2.  **Activar el Job de Despliegue**: Por defecto, el job `deploy` estÃ¡ comentado en `.github/workflows/ci-cd.yml` para evitar ejecuciones fallidas en un repositorio nuevo. Para habilitar el despliegue automÃ¡tico, simplemente descomenta esa secciÃ³n en el archivo. A partir de ese momento, cada `push` a `main` desplegarÃ¡ la aplicaciÃ³n en la nube.

## ğŸš¨ Consideraciones Importantes

âš ï¸ **Este es un proyecto educativo/demostrativo**
- No debe usarse para diagnÃ³sticos mÃ©dicos reales
- Siempre consultar con profesionales mÃ©dicos
- Los resultados son para fines de aprendizaje Ãºnicamente

## ğŸ‰ Â¡Disfruta explorando el mundo del Machine Learning!

Este proyecto demuestra un pipeline completo de ML desde el entrenamiento hasta el deployment, con todas las mejores prÃ¡cticas incluidas. Â¡Perfecto para aprender y expandir! ğŸš€