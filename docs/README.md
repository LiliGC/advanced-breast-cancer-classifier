# ü©∫ Clasificador Avanzado de C√°ncer de Mama

[![CI/CD to Google Cloud](https://github.com/LiliGC/advanced-breast-cancer-classifier/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/LiliGC/advanced-breast-cancer-classifier/actions/workflows/ci-cd.yml)

Una aplicaci√≥n completa de Machine Learning para la clasificaci√≥n de tumores de mama usando Random Forest optimizado, con API Flask y frontend interactivo en Streamlit, todo orquestado con Docker.

## ‚ú® Caracter√≠sticas Principales
- **Dataset**: Wisconsin Breast Cancer Dataset (WDBC) de UCI.
### ü§ñ Modelo de ML Mejorado
- **Random Forest optimizado** con GridSearchCV.
- **Validaci√≥n cruzada** y m√©tricas comprehensivas (Accuracy, ROC-AUC, Recall).
- **An√°lisis de importancia de features** para explicabilidad.
- **Generaci√≥n autom√°tica de visualizaciones**: Curva ROC, matriz de confusi√≥n, etc.
- **Creaci√≥n de casos de ejemplo** (benigno, maligno, l√≠mite) basados en datos reales para demostraciones consistentes.

### üåê API REST Robusta
- **Endpoints**: `health`, `model/info`, `features`, `predict` (individual y batch), y `visualizations`.
- **Validaci√≥n robusta** de datos de entrada y manejo de errores.
- **C√°lculo de contribuci√≥n de features** para cada predicci√≥n.
- **Logging** para seguimiento y depuraci√≥n.

### üéØ Frontend Interactivo
- **4 pesta√±as especializadas**:
  - üîç Predicci√≥n con casos predefinidos
  - üìä An√°lisis de features del dataset
  - üéõÔ∏è Modo manual con sliders interactivos
  - üìà Visualizaciones del modelo
- **Gr√°ficos interactivos** con Plotly
- **M√©tricas en tiempo real**
- **Interfaz intuitiva y profesional** con CSS personalizado.

### üê≥ Contenerizaci√≥n con Docker
- **Pipeline reproducible** con Docker Compose.
- **4 servicios definidos**: `training`, `api`, `frontend`, y `tester`.
- **Inicio automatizado** con un solo script (`start.sh`).
- **Pruebas de integraci√≥n** automatizadas contra la API en un entorno aislado.

### üöÄ CI/CD y Despliegue en la Nube
- **Pipeline Automatizado con GitHub Actions**: Cada `push` a la rama `main` dispara un flujo de trabajo que autom√°ticamente entrena, prueba, construye y despliega la aplicaci√≥n.
- **Despliegue en Google Cloud**: La aplicaci√≥n se despliega en **Google Cloud Run**, una plataforma serverless que escala autom√°ticamente, garantizando alta disponibilidad y eficiencia.
- **Registro de Im√°genes en Artifact Registry**: Las im√°genes de Docker se versionan y almacenan de forma segura en Google Artifact Registry.


## üé• Demostraci√≥n

A continuaci√≥n se presentan breves demostraciones de la aplicaci√≥n.

### Frontend Interactivo

Un vistazo r√°pido a la interfaz de usuario, mostrando una predicci√≥n en tiempo real y el dashboard de resultados.

**‚û°Ô∏è [Ver Demo Completa del Frontend en YouTube](https://youtu.be/sKUN_uGA1IQ)**

### Backend y Pruebas

Demostraci√≥n de la interacci√≥n entre la API, los contenedores y las pruebas automatizadas.

**‚û°Ô∏è [Ver Demo Completa del Backend en YouTube](https://youtu.be/5-SuQPW3JMw)**

## üöÄ Instalaci√≥n y Uso R√°pido (con Docker)

Este proyecto est√° dise√±ado para ejecutarse con Docker, lo que simplifica enormemente la configuraci√≥n y garantiza la reproducibilidad.

**Requisitos:**
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado y en ejecuci√≥n.
- Un terminal que soporte scripts de shell (Git Bash o WSL en Windows).

**Pasos para ejecutar:**

1.  **Clonar el Repositorio:**
    ```bash
    git clone https://github.com/LiliGC/advanced-breast-cancer-classifier.git
    cd advanced-breast-cancer-classifier
    ```

2.  **Ejecutar el Script de Orquestaci√≥n:**
    El m√©todo recomendado es utilizar el script `start.sh` que gestiona todo el ciclo de vida de la aplicaci√≥n local.
    Este script act√∫a como un orquestador que ejecuta los comandos de `docker-compose` en la secuencia correcta para asegurar un inicio limpio y ordenado.

    ```bash
    # En Windows (usando Git Bash o WSL) o en Linux/macOS
    ./start.sh
    ```
    Este script se encargar√° de:
    - Limpiar entornos Docker previos.
    - Construir las im√°genes necesarias.
    - Ejecutar el contenedor de entrenamiento para generar los artefactos del modelo.
    - Levantar la API y el Frontend.
    - Ejecutar las pruebas de integraci√≥n contra la API.

3.  **Acceder a la Aplicaci√≥n:**
    - **Frontend:** Abre tu navegador y ve a `http://localhost:8501`
    - **API Health Check:** `http://localhost:5000/health`

### üõ†Ô∏è Flujo de Desarrollo Diario

Una vez que la aplicaci√≥n ha sido construida y entrenada con `start.sh`, no necesitas ejecutar todo el script cada vez.

- **Para iniciar solo la API y el Frontend (sin re-entrenar):**
  ```bash
  docker-compose up -d api frontend
  ```
- **Para detener todos los servicios:**
  ```bash
  docker-compose down
  ```
#### Limpieza del Entorno

Si deseas eliminar los contenedores, vol√∫menes y las im√°genes construidas para liberar espacio en tu disco:

1.  **Detener y eliminar contenedores y vol√∫menes:**
    ```bash
    docker-compose down -v
    ```

2.  **Eliminar las im√°genes construidas por el proyecto:**
    ```bash
    # Reemplaza 'breast_cancer_project' si tu carpeta de proyecto tiene otro nombre
    docker rmi $(docker images -q 'breast_cancer_project*')
    ```
## üìã Estructura del Proyecto

```
breast_cancer_project/
üìÅ .github/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ workflows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ci-cd.yml          # Flujo de trabajo de CI/CD
‚îú‚îÄ‚îÄ üìÅ breast_cancer_app/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_model.py     # Script de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ api
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.py              # API Flask
|   ‚îú‚îÄ‚îÄ üìÅ frontend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frontend.py         # Frontend Streamlit
‚îú‚îÄ‚îÄ üìÅ tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api.py         # Tests automatizados
‚îú‚îÄ‚îÄ üìÅ requirements/
‚îÇ   ‚îú‚îÄ‚îÄ common.txt              # Dependencias comunes
‚îÇ   ‚îú‚îÄ‚îÄ api.txt                 # Dependencias de la API
‚îÇ   ‚îú‚îÄ‚îÄ frontend.txt            # Dependencias del Frontend
‚îÇ   ‚îî‚îÄ‚îÄ dev.txt                 # Dependencias de desarrollo
‚îú‚îÄ‚îÄ üìÅ artifacts (autom√°tico)
‚îÇ   ‚îú‚îÄ‚îÄ model.pkl  # Modelo entrenado
‚îÇ   ‚îú‚îÄ‚îÄ feature_info.json         # Info de features
‚îÇ   ‚îú‚îÄ‚îÄ model_metrics.json        # M√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ *.png                    # Visualizaciones
|___üìÅ docs/
|    ‚îî‚îÄ‚îÄ DEVELOPMENT_GUIDE.md    # Gu√≠a de evoluci√≥n del desarrollo del proyecto
|‚îÄ‚îÄ Dockerfile                   # Dockerfile para la API
|‚îÄ‚îÄ Docker-compose.yml           # Orquestador de contenedores
|‚îÄ‚îÄ .dockerignore                # Archivos a ignorar en Docker
|‚îÄ‚îÄ .gitignore                   # Archivos a ignorar en Git
|‚îÄ‚îÄ start.sh                     # Script de inicio automatizado
|‚îÄ‚îÄ README.md                    # Documentaci√≥n del proyecto
```

## üîß Componentes Detallados

### 1. ü§ñ Entrenamiento del Modelo (`breast_cancer_app/model/train_model.py`)

**Caracter√≠sticas:**
- **Optimizaci√≥n de hiperpar√°metros** con GridSearchCV.
- **Validaci√≥n cruzada** para evaluar la generalizaci√≥n del modelo.
- **M√©tricas completas**: Accuracy, ROC-AUC, y reporte de clasificaci√≥n.
- **An√°lisis de importancia de features** para explicabilidad.
- **Generaci√≥n autom√°tica de visualizaciones**: Curva ROC, matriz de confusi√≥n, etc.

**Archivos generados en `artifacts/`:**
- `model.pkl` - El modelo entrenado y serializado.
- `roc_curve.png` - Curva ROC del modelo.
- `confusion_matrix.png` - Matriz de confusi√≥n en el set de prueba.

### 2. üåê API REST (`breast_cancer_app/api/api.py`)
- **Endpoints**: `health`, `model/info`, `features`, `predict` (individual y batch), y `visualizations`.
- **Validaci√≥n robusta** de datos de entrada.
- **C√°lculo de contribuci√≥n de features** para cada predicci√≥n.
- **Logging** para seguimiento y depuraci√≥n.

### 3. üéØ Frontend Interactivo (`breast_cancer_app/frontend/frontend.py`)
- **Navegaci√≥n por pesta√±as**: Inicio, Predicci√≥n, An√°lisis del Dataset y Rendimiento del Modelo.
- **Dashboard de resultados** con medidor de confianza y factores clave.
- **Visualizaciones interactivas** con Plotly para explorar el dataset y el modelo.
- **Dise√±o profesional** y responsivo con CSS personalizado.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **ML**: scikit-learn, pandas, numpy
- **Backend**: Flask, Flask-CORS
- **Frontend**: Streamlit, Plotly, Altair
- **Visualizaci√≥n**: matplotlib, seaborn
- **CI/CD**: GitHub Actions
- **Cloud**: Google Cloud Run, Google Artifact Registry
- **Testing**: requests, pytest
- **Utilidades**: joblib, json

## üéØ Casos de Uso

1. **ü©∫ M√©dicos**: Herramienta de apoyo diagn√≥stico
2. **üéì Estudiantes**: Aprender ML aplicado
3. **üë®‚Äçüíª Desarrolladores**: Plantilla para proyectos de ML
4. **üî¨ Investigadores**: An√°lisis de features biom√©dicas

## üìà M√©tricas de Rendimiento

El modelo optimizado t√≠picamente alcanza:
- **Accuracy**: >95%
- **ROC-AUC**: >98%
- **Tiempo de predicci√≥n**: <100ms
- **Memoria**: <50MB

## ü§ù Contribuir

¬°Las contribuciones para mejorar este proyecto son bienvenidas!

**Posibles extensiones:**
- üß† **Explicabilidad Avanzada**: Integrar librer√≠as como **SHAP** para generar visualizaciones de contribuci√≥n m√°s detalladas por predicci√≥n.
- üé® **Mejoras en la UI/UX**: A√±adir temas, mejorar la responsividad o incorporar nuevos tipos de gr√°ficos.
- üìä **Monitoreo del Modelo**: Integrar la API con **Vertex AI Model Monitoring** para detectar *data drift* y *concept drift* en producci√≥n, registrando predicciones en BigQuery.
- üóÑÔ∏è **Historial de Predicciones**: A√±adir una base de datos (como SQLite o PostgreSQL) para guardar y consultar predicciones pasadas.

## üìû Troubleshooting y Soporte

Si encuentras alg√∫n problema al ejecutar el proyecto localmente, sigue estos pasos:

1.  **Aseg√∫rate de usar el script `start.sh`**: Este script garantiza que el entorno se limpie y se construya en el orden correcto. Es la forma recomendada de iniciar la aplicaci√≥n.

2.  **Revisar los Logs de Docker**: Si un servicio no se inicia o se comporta de forma extra√±a, los logs son tu mejor amigo. Abre una nueva terminal y ejecuta:
    ```bash
    # Para ver los logs de la API
    docker-compose logs api

    # Para ver los logs del frontend
    docker-compose logs frontend
    ```

3.  **Reconstrucci√≥n Forzada**: Si has hecho cambios en el c√≥digo y no se reflejan, es posible que necesites forzar una reconstrucci√≥n. El script `start.sh` ya lo hace, pero si quieres hacerlo manualmente:
    ```bash
    docker-compose build --no-cache
    ```

4.  **Abrir un Issue**: Si el problema persiste, la mejor manera de reportarlo es creando un "Issue" en el repositorio de GitHub. Por favor, incluye la salida de los logs y los pasos que seguiste.

## üèóÔ∏è CI/CD y Despliegue en la Nube

### Flujo de Trabajo de CI/CD con GitHub Actions

Este proyecto utiliza un pipeline de Integraci√≥n Continua y Despliegue Continuo (CI/CD) para automatizar todo el ciclo de vida de la aplicaci√≥n.

1.  **Activaci√≥n**: El flujo de trabajo se activa con cada `push` a la rama `main`.
2.  **Entrenamiento y Pruebas**: Se ejecuta el script de entrenamiento para generar los artefactos del modelo y se realizan pruebas de integraci√≥n contra la API.
3.  **Construcci√≥n de Im√°genes**: Se construyen las im√°genes de Docker para la API y el frontend.
4.  **Publicaci√≥n**: Las im√°genes se etiquetan y se suben a Google Artifact Registry.
5.  **Despliegue**: Se despliegan las nuevas versiones de los servicios en Google Cloud Run, actualizando la aplicaci√≥n sin tiempo de inactividad.

### Despliegue en Google Cloud (Configuraci√≥n)

El pipeline est√° preparado para desplegar autom√°ticamente en Google Cloud usando **Workload Identity Federation**, un m√©todo seguro que no requiere claves de servicio de larga duraci√≥n.

**Pasos a seguir en Google Cloud (Resumen):**

1.  **Crear un Proyecto y Habilitar APIs**:
    - Crea un nuevo proyecto en la Consola de Google Cloud.
    - Habilita las siguientes APIs: `Cloud Run API`, `Artifact Registry API`, y `IAM Credentials API`.

2.  **Crear Repositorios en Artifact Registry**:
    - Crea dos repositorios de tipo Docker en Artifact Registry: uno llamado `api-repo` y otro `frontend-repo`.

3.  **Configurar la Identidad para el Pipeline**:
    - **Crea una Cuenta de Servicio (Service Account)**, por ejemplo, `github-actions-deployer`.
    - **Otorga los roles necesarios** a esta cuenta de servicio: `Cloud Run Admin`, `Artifact Registry Writer`, y `Service Account User`.
    - **Crea un Workload Identity Pool y un Provider**. Configura el proveedor para que conf√≠e en tu repositorio de GitHub.
    - **Vincula la Cuenta de Servicio** a la identidad de GitHub, otorg√°ndole el rol `Workload Identity User`. Esto permite que GitHub Actions act√∫e en nombre de tu cuenta de servicio de forma segura.

**Pasos a seguir en GitHub:**

1.  **Configurar los Secretos**: Ve a `Settings > Secrets and variables > Actions` en tu repositorio y a√±ade los siguientes secretos, que obtuviste de los pasos anteriores en Google Cloud:
    - `GCP_PROJECT_ID`
    - `GCP_WORKLOAD_IDENTITY_PROVIDER`
    - `GCP_SERVICE_ACCOUNT`

2.  **Activar el Job de Despliegue**: Por defecto, el job `deploy` est√° comentado en `.github/workflows/ci-cd.yml` para evitar ejecuciones fallidas en un repositorio nuevo. Para habilitar el despliegue autom√°tico, simplemente descomenta esa secci√≥n en el archivo. A partir de ese momento, cada `push` a `main` desplegar√° la aplicaci√≥n en la nube.

## üö® Consideraciones Importantes

‚ö†Ô∏è **Este es un proyecto educativo/demostrativo**
- No debe usarse para diagn√≥sticos m√©dicos reales
- Siempre consultar con profesionales m√©dicos
- Los resultados son para fines de aprendizaje √∫nicamente

## üéâ ¬°Disfruta explorando el mundo del Machine Learning!

Este proyecto demuestra un pipeline completo de ML desde el entrenamiento hasta el deployment, con todas las mejores pr√°cticas incluidas. ¬°Perfecto para aprender y expandir! üöÄ